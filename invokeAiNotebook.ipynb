{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2Z5Qu_o8VtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83325770-e0c1-48e3-a841-59e4770cd85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Check your current GPU assignment\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs2GK5hfn-U3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e599892-e3b8-4a57-ec2a-86fcd6b03b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "drive.mount('/content/drive',)\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sONfdf6Z_Ro8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a747c765-4597-4ad1-9352-a3abd380cc3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Move environment to Python 3.10\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
        "!bash ./py310.sh -b -f -p /usr/local/\n",
        "!python -m ipykernel install --name \"py310\" --user\n",
        "import sys\n",
        "!rm py310.sh\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbI9ZsQHzjqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fd8e71-c931-4bba-f6b7-61c9b23b851d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Download InvokeAI v2.2.4\n",
        "from os.path import exists\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/invoke-ai/InvokeAI.git /content/drive/MyDrive/InvokeAI # Original repo\n",
        "%cd /content/drive/MyDrive/InvokeAI\n",
        "#!git checkout --quiet\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbXcGXYEFSNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89606ee4-a8bb-45c8-ba1f-6d0246744c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Install requirements\n",
        "import gc\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "!wget https://raw.githubusercontent.com/invoke-ai/InvokeAI/main/environments-and-requirements/requirements-base.txt\n",
        "!wget https://raw.githubusercontent.com/invoke-ai/InvokeAI/main/environments-and-requirements/requirements-lin-cuda.txt\n",
        "%cd /content/drive/MyDrive/InvokeAI/\n",
        "!pip install -r requirements-lin-cuda.txt\n",
        "!pip install clean-fid torchtext\n",
        "!pip install transformers\n",
        "gc.collect()\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChIDWxLVHGGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e111ae22-d5f8-4a40-bc89-81141b50ec5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31;1mCOMPLETED !\n"
          ]
        }
      ],
      "source": [
        "#@title Configure InvokeAI (Get your token from Hugging Face)\n",
        "import gc\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "%cd /content/drive/MyDrive/InvokeAI\n",
        "!python scripts/configure_invokeai.py --root /content/drive/MyDrive/InvokeAI\n",
        "gc.collect()\n",
        "time.sleep(5)\n",
        "clear_output()\n",
        "print('\\x1b[31;1mCOMPLETED !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04DVHPxfLOjD"
      },
      "outputs": [],
      "source": [
        "#@title Restart runtime and run InvokeAI and Localtunnel\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "exit()\n",
        "time.sleep(10)\n",
        "#@markdown Create localtunnel subdomain *.loca.lt\n",
        "Subdomain = \"matyinvokeai1\" #@param {type:\"string\"}\n",
        "\n",
        "!kill -9 \"$(<lt.pid)\"\n",
        "!npm install -g localtunnel\n",
        "!nohup lt --port 9191 -h https://loca.lt --subdomain {Subdomain} > lt.log 2>&1 & echo \"$!\" >lt.pid\n",
        "time.sleep(5)\n",
        "print('\\x1b[31;1mSTARTING !')\n",
        "print(open('lt.log', 'r').read())\n",
        "print(open('lt.log', 'r').read())\n",
        "print(open('lt.log', 'r').read())\n",
        "!python /content/drive/MyDrive/InvokeAI/scripts/invoke.py --web --host=0.0.0.0 --port=9191 --cors=https://{Subdomain}.loca.lt --root /content/drive/MyDrive/InvokeAI"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4e870c5c5fe42db7e2c5647ae5af656ff3391bf8c2b729cbf7fa0e16ca8cb5af"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}